// automatically generated by the FlatBuffers compiler, do not modify


// @generated

use core::mem;
use core::cmp::Ordering;

extern crate flatbuffers;
use self::flatbuffers::{EndianScalar, Follow};

// struct Point, aligned to 8
#[repr(transparent)]
#[derive(Clone, Copy, PartialEq)]
pub struct Point(pub [u8; 16]);
impl Default for Point { 
  fn default() -> Self { 
    Self([0; 16])
  }
}
impl core::fmt::Debug for Point {
  fn fmt(&self, f: &mut core::fmt::Formatter) -> core::fmt::Result {
    f.debug_struct("Point")
      .field("h", &self.h())
      .field("x", &self.x())
      .field("y", &self.y())
      .finish()
  }
}

impl flatbuffers::SimpleToVerifyInSlice for Point {}
impl<'a> flatbuffers::Follow<'a> for Point {
  type Inner = &'a Point;
  #[inline]
  unsafe fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
    <&'a Point>::follow(buf, loc)
  }
}
impl<'a> flatbuffers::Follow<'a> for &'a Point {
  type Inner = &'a Point;
  #[inline]
  unsafe fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
    flatbuffers::follow_cast_ref::<Point>(buf, loc)
  }
}
impl<'b> flatbuffers::Push for Point {
    type Output = Point;
    #[inline]
    unsafe fn push(&self, dst: &mut [u8], _written_len: usize) {
        let src = ::core::slice::from_raw_parts(self as *const Point as *const u8, Self::size());
        dst.copy_from_slice(src);
    }
}

impl<'a> flatbuffers::Verifiable for Point {
  #[inline]
  fn run_verifier(
    v: &mut flatbuffers::Verifier, pos: usize
  ) -> Result<(), flatbuffers::InvalidFlatbuffer> {
    use self::flatbuffers::Verifiable;
    v.in_buffer::<Self>(pos)
  }
}

impl<'a> Point {
  #[allow(clippy::too_many_arguments)]
  pub fn new(
    h: u64,
    x: u32,
    y: u32,
  ) -> Self {
    let mut s = Self([0; 16]);
    s.set_h(h);
    s.set_x(x);
    s.set_y(y);
    s
  }

  pub fn h(&self) -> u64 {
    let mut mem = core::mem::MaybeUninit::<<u64 as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[0..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<u64 as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_h(&mut self, x: u64) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[0..].as_mut_ptr(),
        core::mem::size_of::<<u64 as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn x(&self) -> u32 {
    let mut mem = core::mem::MaybeUninit::<<u32 as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[8..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_x(&mut self, x: u32) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[8..].as_mut_ptr(),
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn y(&self) -> u32 {
    let mut mem = core::mem::MaybeUninit::<<u32 as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[12..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_y(&mut self, x: u32) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[12..].as_mut_ptr(),
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
    }
  }

}

pub enum PointTableOffset {}
#[derive(Copy, Clone, PartialEq)]

pub struct PointTable<'a> {
  pub _tab: flatbuffers::Table<'a>,
}

impl<'a> flatbuffers::Follow<'a> for PointTable<'a> {
  type Inner = PointTable<'a>;
  #[inline]
  unsafe fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
    Self { _tab: flatbuffers::Table::new(buf, loc) }
  }
}

impl<'a> PointTable<'a> {
  pub const VT_H: flatbuffers::VOffsetT = 4;
  pub const VT_X: flatbuffers::VOffsetT = 6;
  pub const VT_Y: flatbuffers::VOffsetT = 8;

  #[inline]
  pub unsafe fn init_from_table(table: flatbuffers::Table<'a>) -> Self {
    PointTable { _tab: table }
  }
  #[allow(unused_mut)]
  pub fn create<'bldr: 'args, 'args: 'mut_bldr, 'mut_bldr>(
    _fbb: &'mut_bldr mut flatbuffers::FlatBufferBuilder<'bldr>,
    args: &'args PointTableArgs
  ) -> flatbuffers::WIPOffset<PointTable<'bldr>> {
    let mut builder = PointTableBuilder::new(_fbb);
    builder.add_h(args.h);
    builder.add_y(args.y);
    builder.add_x(args.x);
    builder.finish()
  }


  #[inline]
  pub fn h(&self) -> u64 {
    // Safety:
    // Created from valid Table for this object
    // which contains a valid value in this slot
    unsafe { self._tab.get::<u64>(PointTable::VT_H, Some(0)).unwrap()}
  }
  #[inline]
  pub fn x(&self) -> u32 {
    // Safety:
    // Created from valid Table for this object
    // which contains a valid value in this slot
    unsafe { self._tab.get::<u32>(PointTable::VT_X, Some(0)).unwrap()}
  }
  #[inline]
  pub fn y(&self) -> u32 {
    // Safety:
    // Created from valid Table for this object
    // which contains a valid value in this slot
    unsafe { self._tab.get::<u32>(PointTable::VT_Y, Some(0)).unwrap()}
  }
}

impl flatbuffers::Verifiable for PointTable<'_> {
  #[inline]
  fn run_verifier(
    v: &mut flatbuffers::Verifier, pos: usize
  ) -> Result<(), flatbuffers::InvalidFlatbuffer> {
    use self::flatbuffers::Verifiable;
    v.visit_table(pos)?
     .visit_field::<u64>("h", Self::VT_H, false)?
     .visit_field::<u32>("x", Self::VT_X, false)?
     .visit_field::<u32>("y", Self::VT_Y, false)?
     .finish();
    Ok(())
  }
}
pub struct PointTableArgs {
    pub h: u64,
    pub x: u32,
    pub y: u32,
}
impl<'a> Default for PointTableArgs {
  #[inline]
  fn default() -> Self {
    PointTableArgs {
      h: 0,
      x: 0,
      y: 0,
    }
  }
}

pub struct PointTableBuilder<'a: 'b, 'b> {
  fbb_: &'b mut flatbuffers::FlatBufferBuilder<'a>,
  start_: flatbuffers::WIPOffset<flatbuffers::TableUnfinishedWIPOffset>,
}
impl<'a: 'b, 'b> PointTableBuilder<'a, 'b> {
  #[inline]
  pub fn add_h(&mut self, h: u64) {
    self.fbb_.push_slot::<u64>(PointTable::VT_H, h, 0);
  }
  #[inline]
  pub fn add_x(&mut self, x: u32) {
    self.fbb_.push_slot::<u32>(PointTable::VT_X, x, 0);
  }
  #[inline]
  pub fn add_y(&mut self, y: u32) {
    self.fbb_.push_slot::<u32>(PointTable::VT_Y, y, 0);
  }
  #[inline]
  pub fn new(_fbb: &'b mut flatbuffers::FlatBufferBuilder<'a>) -> PointTableBuilder<'a, 'b> {
    let start = _fbb.start_table();
    PointTableBuilder {
      fbb_: _fbb,
      start_: start,
    }
  }
  #[inline]
  pub fn finish(self) -> flatbuffers::WIPOffset<PointTable<'a>> {
    let o = self.fbb_.end_table(self.start_);
    flatbuffers::WIPOffset::new(o.value())
  }
}

impl core::fmt::Debug for PointTable<'_> {
  fn fmt(&self, f: &mut core::fmt::Formatter<'_>) -> core::fmt::Result {
    let mut ds = f.debug_struct("PointTable");
      ds.field("h", &self.h());
      ds.field("x", &self.x());
      ds.field("y", &self.y());
      ds.finish()
  }
}
